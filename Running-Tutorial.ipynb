{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Diffusion-Wavelet: Interpretable Diffusion and Progressive Distillation forTime Series Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary packages and functions call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(\"C:/Users/geminia/Desktop/Diffusion-FS\")\n",
    "from Engine.trainer import Engine\n",
    "from Utils.metric_utils import visualization\n",
    "from Datasets.create_dataloader import create_dataloader\n",
    "from Utils.io_utils import load_yaml_config, instantiate_from_config, build_from_teacher\n",
    "from Utils.fix_tensors import clean_keys, reshape_tensors\n",
    "from Models.interpretable_diffusion.model_utils import unnormalize_to_zero_to_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Args_Example:\n",
    "    def __init__(self) -> None:\n",
    "        self.config_path = './Configs/stocks.yaml'\n",
    "        self.save_dir = './Save'\n",
    "        self.gpu = 0\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "args =  Args_Example()\n",
    "configs = load_yaml_config(args.config_path)\n",
    "device = torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dl_info = create_dataloader(configs, args)\n",
    "model = instantiate_from_config(configs['model']).to(device) \n",
    "teacher = Engine(config=configs, args=args, model=model, dataloader=dl_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distillation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##New\n",
    "teacher_keys = teacher.model.state_dict()\n",
    "numsteps = teacher.model.num_timesteps\n",
    "changeable = clean_keys(teacher_keys,numsteps)\n",
    "\n",
    "reshape_tensors(teacher_keys, changeable)\n",
    "\n",
    "config_0, model_0 = build_from_teacher(config=configs, device=device)\n",
    "\n",
    "student = Engine(config=config_0, args=args, model=model_0, dataloader=dl_info)\n",
    "\n",
    "student.model.load_state_dict(teacher_keys)\n",
    "student.model.teacher = teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.distill()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dl_info['dataset']\n",
    "seq_length, feature_dim = dataset.window, dataset.var_num\n",
    "#ori_data = np.load(os.path.join(dataset.dir, f\"stock_ground_truth_{seq_length}_train.npy\"))\n",
    "ori_data = np.load(os.path.join(dataset.dir, f\"stock_norm_truth_24_train.npy\"))  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = teacher.sample(num=len(dataset), size_every=2001, shape=[seq_length, feature_dim])\n",
    "if dataset.auto_norm:\n",
    "    fake_data = unnormalize_to_zero_to_one(fake_data)\n",
    "    np.save(os.path.join(args.save_dir, f'ddpm_fake_stock.npy'), fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dl_info['dataset']\n",
    "seq_length, feature_dim = dataset.window, dataset.var_num\n",
    "#ori_data = np.load(os.path.join(dataset.dir, f\"stock_ground_truth_{seq_length}_train.npy\"))\n",
    "ori_data = np.load(os.path.join(dataset.dir, f\"stock_norm_truth_24_train.npy\"))  # Uncomment the line if dataset other than Sine is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = teacher.sample(num=len(dataset), size_every=4001, shape=[seq_length, feature_dim])\n",
    "if dataset.auto_norm:\n",
    "    fake_data = unnormalize_to_zero_to_one(fake_data)\n",
    "    np.save(os.path.join(args.save_dir, f'ddpm_fake_train_stock.npy'), fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data_0 = student.sample(num=len(dataset), size_every=4001, shape=[seq_length, feature_dim])\n",
    "if dataset.auto_norm:\n",
    "    fake_data_0 = unnormalize_to_zero_to_one(fake_data_0)\n",
    "    np.save(os.path.join(args.save_dir, f'ddpm_fake_stock1.npy'), fake_data_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "We visualize the original and synthetic data distributions using PCA, tSNE and Density analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(ori_data=ori_data, generated_data=fake_data, analysis='pca', compare=ori_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(ori_data=ori_data, generated_data=fake_data, analysis='tsne', compare=ori_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(ori_data=ori_data, generated_data=fake_data, analysis='kernel', compare=ori_data.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
